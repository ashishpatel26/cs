{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 2 - Quiz: Data storage solutions, and ApacheSpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>**1.**\n",
    "\n",
    "rdd = sc.parallelize(range(100))\n",
    "\n",
    "rdd2 = range(100)\n",
    "\n",
    "Please consider the following code.\n",
    "\n",
    "Where is data in \"rdd\" stored physically?\n",
    " \n",
    "**In main-memory of ApacheSpark worker nodes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>**2.**\n",
    "\n",
    "rdd = sc.parallelize(range(100))\n",
    "\n",
    "rdd2 = range(100)\n",
    "\n",
    "Please consider the following code.\n",
    "\n",
    "Where is data in \"rdd2\" stored physically?\n",
    " \n",
    "**On the local Driver machine**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>**3.**\n",
    "\n",
    "What is the parallel version of the following code?\n",
    "\n",
    "len(range(9999999999))\n",
    " \n",
    "**sc.parallelize(range(9999999999)).count()**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>**4.**\n",
    "\n",
    "Which storage solutions support seamless modification of schemas? (Select all that apply)\n",
    " \n",
    "**ObjectStorage**\n",
    "\n",
    "**NoSQL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>**5.**\n",
    "\n",
    "Which storage solutions support dynamic scaling on storage? (Select all that apply)\n",
    " \n",
    "**ObjectStorage**\n",
    "\n",
    "**NoSQL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>**6.**\n",
    "\n",
    "Which storage solutions support normalization and integrity checks on data out of the box? (Select all that apply)\n",
    " \n",
    "**SQL/Relational Databases**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 2 - Quiz: Programming language options and functional programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>**1.**\n",
    "\n",
    "Which programming languages can be used for using GraphX, the ApacheSpark graph processing engine? (Select all that apply)\n",
    " \n",
    "**Scala**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>**2.**\n",
    "\n",
    "What is the result of the following code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):    \n",
    "  return (x+2)*2    \n",
    "l = [1,2,3,4]\n",
    "map(f,l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[6, 8, 10, 12]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>**3.**\n",
    "\n",
    "What is the result of the following python code running on top of ApacheSpark (pyspark) ?\n",
    "\n",
    "sc.parallelize([1,2,3,4,5]).reduce(lambda a,b:a+b)\n",
    " \n",
    "**15**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>**4.**\n",
    "\n",
    "What has to be changed in an ApacheSpark program using only functions on the RDD API which has been tested on 1 KB of data if it should run on 1 PB of data?\n",
    " \n",
    "**Nothing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>**5.**\n",
    "\n",
    "In which programming languages do you find the most libraries for data science specific tasks?\n",
    " \n",
    "**Python**\n",
    "\n",
    "**R**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>**6.**\n",
    "\n",
    "Data frames are the central data structure in R and also in python's Pandas. But they are not using ApacheSpark in the background, therefore what is the major limitation of data frames used in R or python's Pandas?\n",
    " \n",
    "**They are not running in parallel on multiple machines**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 2 - Quiz: ApacheSparkSQL, Cloudant, and the End to End Scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>**1.**\n",
    "\n",
    "We are simulating an IoT device. What framework are we using for that?\n",
    " \n",
    "**NodeRED**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>**2.**\n",
    "\n",
    "What statements are true about cloudant? (Select all that apply)\n",
    "\n",
    "**Cloudant is based on ApacheCouchDB**\n",
    "\n",
    "**Cloudant is a NoSQL database**\n",
    "\n",
    "**BigCouch is a component between the client and a set of CouchDB services used for horizontal scaling**\n",
    "\n",
    "**Cloudant is meant for storing JSON documents effectively**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>**3.**\n",
    "\n",
    "Please have a look at the following flow:\n",
    "\n",
    "![picture alt](https://d3c33hcgiwev3.cloudfront.net/imageAssetProxy.v1/dm68ZrjHEeaoWA59UGLCkA_cd8ce29bab88651ed25dc1eaaf9df1d7_Screen-Shot-2016-12-02-at-20.41.55.png?expiry=1541376000000&hmac=0uuObPP-eRsGO8xtXreQKcxxBE7C7rRXZVqAWiA16j4)\n",
    "\n",
    " \n",
    "**Mechanical Sensor Simulator**\n",
    "\n",
    "**Fluid Simulator**\n",
    "\n",
    "**Voltage Sensor Simulator**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>**4.**\n",
    "\n",
    "In the \"End-to-End Scenario\", where does all the data get stored in?\n",
    " \n",
    "**Cloudant (ApacheCouchDB)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>**5.**\n",
    "\n",
    "How does the Catalyst optimizer work internally?\n",
    "\n",
    "Abbreviations:\n",
    "\n",
    "AST - Abstract Syntax Tree\n",
    "\n",
    "LEP - Logical Execution Plan\n",
    "\n",
    "PEP - Physical Execution Plan\n",
    " \n",
    "**A LEP is created from an SQL AST. This LEP is transformed (optimised). Then multiple PEPs are created from the optimised LEP. Finnaly, based on cost based statistics an optimal PEP is chosen to be executed.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>**6.**\n",
    "\n",
    "What is the advantage of using ApacheSparkSQL over RDDs? (select all that apply)\n",
    " \n",
    "**Catalyst and Tungsten are able to optimise the execution, so are more likely to execute more quickly than if you would had implemented something equivalent using the RDD API.**\n",
    "\n",
    "**The API is simpler and doesn't require specific functional programming skills**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
